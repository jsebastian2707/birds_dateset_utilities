{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "IDs6QnrrcXQX",
   "metadata": {
    "id": "IDs6QnrrcXQX"
   },
   "source": [
    "# entrenar el primer modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QcOVKt5PcIyB",
   "metadata": {
    "id": "QcOVKt5PcIyB"
   },
   "source": [
    "## cargar librerias y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79dca8-a745-457b-81cb-e7774dadc829",
   "metadata": {
    "id": "1c79dca8-a745-457b-81cb-e7774dadc829"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "# Cargar constantes desde el archivo JSON\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Constantes\n",
    "CONST_BASE_FOLDER = config[\"CONST_BASE_FOLDER\"]\n",
    "CONST_OUTPUT_WIDTH = config[\"CONST_OUTPUT_WIDTH\"]\n",
    "#CONST_FILLBG_COLOR = tuple(config[\"CONST_FILLBG_COLOR\"])\n",
    "PRODUCTION_DATASET_FOLDER = os.path.join(CONST_BASE_FOLDER, \"production_dataset_52_resize_2/transformed_dataset\")\n",
    "TRAIN_DATA_DIR = os.path.join(PRODUCTION_DATASET_FOLDER, 'train') \n",
    "VALIDATION_DATA_DIR = os.path.join(PRODUCTION_DATASET_FOLDER, 'valid')\n",
    "batch_size = 32\n",
    "# Definir el número de épocas\n",
    "epochs = 50\n",
    "\n",
    "# Definir el tamaño de las imágenes\n",
    "width_shape = 224\n",
    "height_shape = 224\n",
    "\n",
    "# Definir el número de clases\n",
    "num_classes = 52  # Ajustar según el número de clases en tu dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V6K-bJjIdj-Y",
   "metadata": {
    "id": "V6K-bJjIdj-Y"
   },
   "source": [
    "## definir los generadores de imagenes y los generadores de imagenes por lotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03029fc6-1f49-4efb-9d50-8b30f520bde9",
   "metadata": {
    "id": "03029fc6-1f49-4efb-9d50-8b30f520bde9"
   },
   "outputs": [],
   "source": [
    "# Definir el generador de imágenes para el conjunto de entrenamiento con aumentos de datos\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,               # Rango de grados para rotación aleatoria\n",
    "    zoom_range=0.2,                  # Rango de zoom aleatorio\n",
    "    width_shift_range=0.1,           # Rango de desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.1,          # Rango de desplazamiento vertical aleatorio\n",
    "    horizontal_flip=True,            # Volteo horizontal aleatorio\n",
    "    vertical_flip=False,             # No se aplica volteo vertical\n",
    "    preprocessing_function=preprocess_input)  # Función de preprocesamiento\n",
    "\n",
    "# Definir el generador de imágenes para el conjunto de validación con los mismos aumentos de datos\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# Crear un generador de lotes de imágenes para el conjunto de entrenamiento\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,                  # Directorio que contiene las imágenes de entrenamiento\n",
    "    target_size=(width_shape, height_shape),  # Tamaño al que se redimensionarán las imágenes\n",
    "    batch_size=batch_size,           # Tamaño del lote\n",
    "    class_mode='categorical')        # Modo de clasificación para imágenes categóricas\n",
    "\n",
    "# Crear un generador de lotes de imágenes para el conjunto de validación\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,             # Directorio que contiene las imágenes de validación\n",
    "    target_size=(width_shape, height_shape),  # Tamaño al que se redimensionarán las imágenes\n",
    "    batch_size=batch_size,           # Tamaño del lote\n",
    "    class_mode='categorical')        # Modo de clasificación para imágenes categóricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dzw0IcUPb2TN",
   "metadata": {
    "id": "dzw0IcUPb2TN"
   },
   "source": [
    "# entrenar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8f050-95c7-4d3b-9ae2-1eec017247e8",
   "metadata": {
    "id": "43d8f050-95c7-4d3b-9ae2-1eec017247e8"
   },
   "outputs": [],
   "source": [
    "# Definir el número de muestras de entrenamiento y validación\n",
    "nb_train_samples = 2805\n",
    "nb_validation_samples = 90\n",
    "\n",
    "# Definir la entrada de la red neuronal con el tamaño de las imágenes\n",
    "image_input = Input(shape=(width_shape, height_shape, 3))\n",
    "\n",
    "# Cargar el modelo VGG16 preentrenado con pesos ajustados desde ImageNet\n",
    "model = VGG16(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "\n",
    "# Obtener la salida de la penúltima capa densa del modelo VGG16 (fc2)\n",
    "last_layer = model.get_layer('fc2').output\n",
    "\n",
    "# Añadir una nueva capa densa al final del modelo para la clasificación multiclase con regularización L2 (Evita sobreajuste)\n",
    "out = Dense(num_classes, activation='softmax', kernel_regularizer='l2', name='output')(last_layer)\n",
    "\n",
    "# Crear un nuevo modelo personalizado que toma la entrada de la imagen y produce la salida clasificada\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "\n",
    "# Congelar todas las capas del modelo, excepto la capa densa añadida\n",
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compilar el modelo con una función de pérdida, optimizador y métricas especificadas\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Mostrar un resumen del modelo que incluye la arquitectura y el número de parámetros\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "# Entrenar el modelo utilizando generadores de datos para el conjunto de entrenamiento y validación\n",
    "model_history = custom_vgg_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,  # Número de pasos por época de entrenamiento\n",
    "    validation_steps=nb_validation_samples//batch_size)  # Número de pasos por época de validación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CUSEUVxIeMBw",
   "metadata": {
    "id": "CUSEUVxIeMBw"
   },
   "source": [
    "## busca si ya hay modelos con el mismo nombre y guarda el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba98194-47fd-4212-8628-296147a9a8d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "6ba98194-47fd-4212-8628-296147a9a8d9",
    "outputId": "2b2e195b-625e-42d8-c3ff-bcc119ebaf76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_VGG16_v.keras\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'custom_vgg_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2b0f2aec634e>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Guardar el modelo con el nombre único en el directorio correcto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcustom_vgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_vgg_model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Nombre base del modelo\n",
    "model_name = \"model_VGG16_v\"\n",
    "\n",
    "# Extensión del archivo\n",
    "file_extension = \".keras\"\n",
    "\n",
    "# Directorio donde se guardarán los modelos\n",
    "model_directory = \"models/\"\n",
    "\n",
    "# Inicializar contador\n",
    "counter = 1\n",
    "\n",
    "# Generar el nombre completo del archivo\n",
    "file_name = model_name + file_extension\n",
    "\n",
    "ruta=model_directory + file_name\n",
    "print(ruta)\n",
    "# Verificar si el modelo ya está guardado\n",
    "while os.path.exists(model_directory + file_name):\n",
    "\n",
    "    # Si el archivo existe, agregar un número al final del nombre del modelo\n",
    "    file_name = f\"{model_name}{counter}{file_extension}\"\n",
    "    counter += 1\n",
    "\n",
    "# Guardar el modelo con el nombre único en el directorio correcto\n",
    "custom_vgg_model.save(model_directory + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa42dc0-0421-403b-9b6f-e22a4b571ebb",
   "metadata": {
    "id": "8fa42dc0-0421-403b-9b6f-e22a4b571ebb"
   },
   "outputs": [],
   "source": [
    "def plotTraining(hist, epochs, typeData):\n",
    "\n",
    "    # Seleccionar la figura y establecer el tamaño\n",
    "    # Dependiendo del tipo de datos (loss o accuracy), se elige la figura correspondiente\n",
    "\n",
    "    if typeData==\"loss\":\n",
    "        plt.figure(1,figsize=(10,5))\n",
    "        yc=hist.history['loss']\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.plot(xc,yc,'-r',label='Loss Training')\n",
    "    if typeData==\"accuracy\":\n",
    "        plt.figure(2,figsize=(10,5))\n",
    "        yc=hist.history['accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i]=100*yc[i]\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "        plt.plot(xc,yc,'-r',label='Accuracy Training')\n",
    "    if typeData==\"val_loss\":\n",
    "        plt.figure(1,figsize=(10,5))\n",
    "        yc=hist.history['val_loss']\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.plot(xc,yc,'--b',label='Loss Validate')\n",
    "    if typeData==\"val_accuracy\":\n",
    "        plt.figure(2,figsize=(10,5))\n",
    "        yc=hist.history['val_accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i]=100*yc[i]\n",
    "        xc=range(epochs)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "        plt.plot(xc,yc,'--b',label='Training Validate')\n",
    "\n",
    "\n",
    "    plt.rc('xtick',labelsize=24)\n",
    "    plt.rc('ytick',labelsize=24)\n",
    "    plt.rc('legend', fontsize=18)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of Epochs',fontsize=24)\n",
    "    plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a9a72-77d1-4cb4-8cb8-5fe634fa7097",
   "metadata": {
    "id": "2e1a9a72-77d1-4cb4-8cb8-5fe634fa7097"
   },
   "outputs": [],
   "source": [
    "plotTraining(model_history,epochs,\"loss\")\n",
    "plotTraining(model_history,epochs,\"accuracy\")\n",
    "plotTraining(model_history,epochs,\"val_loss\")\n",
    "plotTraining(model_history,epochs,\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52836a92-00ab-4163-b525-58b7feb1a29b",
   "metadata": {
    "id": "52836a92-00ab-4163-b525-58b7feb1a29b"
   },
   "outputs": [],
   "source": [
    "# parte del codigo para consumir un modelo\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "\n",
    "names = ['CYANOCORAX YNCAS', 'PIRANGA RUBRA', 'PITANGUS SULPHURATUS', 'PYROCEPHALUS RUBINUS', 'RUPORNIS MAGNIROSTRIS', 'SICALIS FLAVEOLA', 'THRAUPIS EPISCOPUS', 'TIARIS OLIVACEUS', 'TYRANNUS MELANCHOLICUS', 'ZONOTRICHIA CAPENSIS', 'CATHARTES AURA', 'COEREBA FLAVEOLA', 'COLUMBA LIVIA', 'CORAGYPS ATRATUS', 'CROTOPHAGA SULCIROSTRIS', 'CYANOCORAX YNCAS', 'EGRETTA THULA', 'FALCO PEREGRINUS', 'FALCO SPARVERIUS', 'HIRUNDO RUSTICA', 'PANDION HALIAETUS', 'PILHERODIUS PILEATUS', 'PITANGUS SULPHURATUS', 'PYRRHOMYIAS CINNAMOMEUS', 'RYNCHOPS NIGER', 'SETOPHAGA FUSCA', 'SYNALLAXIS AZARAE', 'TYRANNUS MELANCHOLICUS']\n",
    "\n",
    "# Cargar el modelo\n",
    "modelt = load_model('models/optimizado.keras')\n",
    "#modelt = custom_vgg_model\n",
    "\n",
    "# Ruta de la imagen de prueba\n",
    "imaget_path = \"ImagenPrueba_sin_fondo.jpg\"\n",
    "\n",
    "# Leer la imagen, cambiar tamaño y preprocesar\n",
    "imaget=cv2.resize(cv2.imread(imaget_path), (width_shape, height_shape), interpolation = cv2.INTER_AREA)\n",
    "xt = np.asarray(imaget)\n",
    "xt=preprocess_input(xt)\n",
    "xt = np.expand_dims(xt,axis=0)\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "preds = modelt.predict(xt)\n",
    "\n",
    "# Obtener la clase predicha y su porcentaje de confianza\n",
    "predicted_class_index = np.argmax(preds)\n",
    "predicted_class_name = names[predicted_class_index]\n",
    "confidence_percentage = preds[0][predicted_class_index] * 100\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f'Clase predicha: {predicted_class_name}')\n",
    "print(f'Porcentaje de confianza: {confidence_percentage:.2f}%')\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(cv2.cvtColor(np.asarray(imaget), cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4afb1-ab54-4f0f-bc51-4403d71fa044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "73d4afb1-ab54-4f0f-bc51-4403d71fa044",
    "outputId": "c6345615-afcd-464e-e74d-0410056f96de"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-50f996050ebd>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dataset/test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m test_generator = test_datagen.flow_from_directory(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "##mostrar estadisticas\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "names = ['CATHARTES AURA', 'COEREBA FLAVEOLA', 'COLUMBA LIVIA', 'CORAGYPS ATRATUS', 'CROTOPHAGA SULCIROSTRIS', 'CYANOCORAX YNCAS', 'EGRETTA THULA', 'FALCO PEREGRINUS', 'FALCO SPARVERIUS', 'HIRUNDO RUSTICA', 'PANDION HALIAETUS', 'PILHERODIUS PILEATUS', 'PITANGUS SULPHURATUS', 'PYRRHOMYIAS CINNAMOMEUS', 'RYNCHOPS NIGER', 'SETOPHAGA FUSCA', 'SYNALLAXIS AZARAE', 'TYRANNUS MELANCHOLICUS']\n",
    "\n",
    "\n",
    "\n",
    "test_data_dir = 'dataset/test'\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "custom_Model= load_model(model_directory + file_name)\n",
    "\n",
    "predictions = custom_Model.predict(test_generator)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_real = test_generator.classes\n",
    "\n",
    "\n",
    "matc=confusion_matrix(y_real, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_real,y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5034d-75a4-4453-bec8-986bf0167733",
   "metadata": {
    "id": "fbd5034d-75a4-4453-bec8-986bf0167733"
   },
   "source": [
    "# todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754076b-6e3f-4ee9-adb9-fdfe43abc976",
   "metadata": {
    "id": "2754076b-6e3f-4ee9-adb9-fdfe43abc976"
   },
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir el número de muestras de entrenamiento y validación\n",
    "nb_train_samples = 2621\n",
    "nb_validation_samples = 738\n",
    "\n",
    "# Definir el número de épocas\n",
    "epochs = 50\n",
    "\n",
    "# Definir el tamaño de las imágenes\n",
    "width_shape = 224\n",
    "height_shape = 224\n",
    "\n",
    "# Definir el número de clases\n",
    "num_classes = 18  # Ajustar según el número de clases en tu dataset\n",
    "\n",
    "# Directorios de datos de entrenamiento y validación\n",
    "train_data_dir = 'datasetpreprocesado/train'\n",
    "validation_data_dir = 'datasetpreprocesado/valid'\n",
    "\n",
    "# Función para crear y entrenar el modelo\n",
    "def create_and_train_vgg16_model(learning_rate, l2_regularization, batch_size):\n",
    "    # Crear generadores de datos con el batch_size proporcionado\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(width_shape, height_shape),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = valid_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(width_shape, height_shape),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Definir la entrada de la red neuronal con el tamaño de las imágenes\n",
    "    image_input = Input(shape=(width_shape, height_shape, 3))\n",
    "\n",
    "    # Cargar el modelo VGG16 preentrenado con pesos ajustados desde ImageNet\n",
    "    model = VGG16(input_tensor=image_input, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Aplanar la salida del VGG16\n",
    "    x = Flatten()(model.output)\n",
    "\n",
    "    # Añadir una nueva capa densa al final del modelo para la clasificación multiclase con regularización L2\n",
    "    out = Dense(num_classes, activation='softmax', kernel_regularizer='l2')(x)\n",
    "\n",
    "    # Crear un nuevo modelo personalizado que toma la entrada de la imagen y produce la salida clasificada\n",
    "    custom_vgg_model = Model(inputs=model.input, outputs=out)\n",
    "\n",
    "    # Congelar todas las capas del modelo base VGG16\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compilar el modelo con una función de pérdida, optimizador y métricas especificadas\n",
    "    custom_vgg_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    # Mostrar un resumen del modelo que incluye la arquitectura y el número de parámetros\n",
    "    custom_vgg_model.summary()\n",
    "\n",
    "    # Medir el tiempo y el uso de CPU/memoria antes de entrenar\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    start_memory = psutil.virtual_memory().used\n",
    "\n",
    "    # Crear los callbacks para Early Stopping y guardar el mejor modelo\n",
    "    checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Entrenar el modelo utilizando generadores de datos para el conjunto de entrenamiento y validación\n",
    "    model_history = custom_vgg_model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "    # Medir el tiempo y el uso de CPU/memoria después de entrenar\n",
    "    end_time = time.time()\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_memory = psutil.virtual_memory().used\n",
    "\n",
    "    # Calcular métricas de tiempo y uso de recursos\n",
    "    elapsed_time = end_time - start_time\n",
    "    cpu_usage = end_cpu - start_cpu\n",
    "    memory_usage = end_memory - start_memory\n",
    "\n",
    "    print(f\"Tiempo transcurrido para el entrenamiento: {elapsed_time} segundos\")\n",
    "    print(f\"Uso de CPU durante el entrenamiento: {cpu_usage}%\")\n",
    "    print(f\"Aumento en uso de memoria: {memory_usage / (1024 ** 3)} GB\")\n",
    "\n",
    "    return model_history, elapsed_time, cpu_usage, memory_usage\n",
    "\n",
    "# Definir rangos de búsqueda para hiperparámetros\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "l2_regularizations = [0.01, 0.05, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "# Variables para almacenar los mejores hiperparámetros y su rendimiento\n",
    "best_val_accuracy = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula\n",
    "for learning_rate in learning_rates:\n",
    "    for l2_regularization in l2_regularizations:\n",
    "        for batch_size in batch_sizes:\n",
    "            # Crear y entrenar el modelo con los hiperparámetros actuales\n",
    "            model_history, elapsed_time, cpu_usage, memory_usage = create_and_train_vgg16_model(learning_rate, l2_regularization, batch_size)\n",
    "\n",
    "            # Obtener la mejor precisión de validación de esta combinación de hiperparámetros\n",
    "            val_accuracy = np.max(model_history.history['val_accuracy'])\n",
    "\n",
    "            # Imprimir los resultados\n",
    "            print(f\"Resultados para lr={learning_rate}, l2={l2_regularization}, batch_size={batch_size}:\")\n",
    "            print(f\"Tiempo: {elapsed_time} segundos, CPU: {cpu_usage}%, Memoria: {memory_usage / (1024 ** 3)} GB\")\n",
    "            print(f\"Precisión de validación: {val_accuracy}\")\n",
    "\n",
    "            # Actualizar los mejores hiperparámetros si la precisión de validación mejora\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_hyperparams = {\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'l2_regularization': l2_regularization,\n",
    "                    'batch_size': batch_size,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'cpu_usage': cpu_usage,\n",
    "                    'memory_usage': memory_usage\n",
    "                }\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y su rendimiento\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_hyperparams)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
